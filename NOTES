I now have the gradient calculation.  It seems to be correct.
Now, I believe that I should go through and reconstruct the
states on each face according to

u^L_{i,j+1/2} = u_{i,j} + (grad(u) . rvec) phi(r)

where r = (grad(u) . rvec)_L / (grad(u) . rvec)_R

This will construct the interface states which will
then be used to solve the Riemann problem using Roe's
approximate scheme.

After that, all I need to do is change the
update subroutine so that the fluxes from all the interfaces
are accounted for in the computation of the residual.  Then,
I need to implement boundary conditions.  I'm going to need
slip wall and farfield for now probably.  Then, the Euler
solver should be done.

-------------------------

Something is wrong... I'm getting negative densities after
the first step which is causing NaNs.  I need to double
check the conversions from primitive to conservative,
reconstruction and switch from the barth limiter to the
minmod limiter.  There is a good explanation of the minmod
limiter in Leveque's book.

-------------------------

It seems that the information is not being communicated from
the farfield boundaries.  The fluxes aren't changing, which
indicates that the boundary condition is being enforced,
and it seems that the reconstruction is working okay...
When I print out reconstructed values, they seem reasonable.
One idea is to hardwire the reconstruction for the cartesian
grid case being solved.  Then I might be able to figure out
if the reconstruction is what is causing the issue.

-------------------------

The sign on some of the fluxes was wrong.  Now, the farfield
boundaries seem wrong.  It is because I am changing the sign
of the fluxes in the final loop.  I need to change the enforcement
of the farfield boundary conditions so that they use the inward pointing face normal!!!!!

-------------------------

Added Barth-Jespersen limiter formulation using their original
paper.  Something is wrong though because I get NaNs after the
first few timesteps.

-------------------------

I've tracked down the NaNs to the residual_inv subroutine.
When using RK4 to march in time, the NaNs arise after the first
stage of the RK4 process.  There must be something inside the select
case that is screwing things up.  This doesn't happen if the limiter
is set to "none".  The limiter variable phi is always real and finite.
I removed the multiplication by phi in the reconstruction step and
I'm still getting NaNs after the first stage of RK4.  This leads me
to believe that there is some unintended side-effect happening in the
code.  I need to find the side-effect and remove it.  I know that it is
isolated to the portion of the select case that matches "barth".

-------------------------

It seems that something about the slope limited reconstruction
causes the Riemann solver to return NaNs for the fluxes....  I'm
not sure how or why this is happening.  I've gotta figure out how
to implement the minmod slope limiter instead.  This is strange because
the limiter is returning between 0 and 1 at all times.  I printed out
the values and everything seemed reasonable.  I'm not sure why the
Riemann solver is returning NaNs.

-------------------------

12-22-2016
I believe the NaNs are coming about as a result of the slip wall
boundary condition.  I need to add another boundary condition which
strongly enforcing the slip wall bc.  This should be do-able
by setting up another boundary condition option.  I can't find anything
wrong with the Euler or RK4 time stepping.  I can't find anything
wrong with the slope-limited reconstruction...  I don't know what is
wrong.

-------------------------

12-23-2016 - 12:46 pm
I fixed some of the NaNs.  There were bugs in the barth limiter portion
of the code.  The barth limiter now works properly it seems.
I tried the barth limiter on the isentropic vortex case.  It works,
but is very diffusive.  The bugs were associated with copying the
code I wrote for the barth limiter and not changing some of the edges_v
to edges_h. The problem now is that the timestep I have to use is very small.
Also, it seems that when I get NaNs, they come from the horizontal interfaces.
I'm not sure what exactly is happening.  To try to fix it I am going to
finish implementing strong enforcement of slip wall BCs to all boundaries.

-------------------------

12-23-2016 - 11:02 pm
I found another bug in the enforcement of the slip wall BCs. Some
of the indices in the slip wall bc were wrong.  I was looping over
i instead of j in some cases.  I think there still might be something
wrong with the horizontal interfaces.  I need to debug more tomorrow.

-------------------------

12-24-2016 - 2:17 pm
I checked the 2D numerical solution against the 1D numerical solution
and the exact solution for the shock tube case.  It is weird.  It seems
that the results don't match.  I think I know what it is... I think that
I am inadvertently setting extrapolate BCs in the 1D code.  Are the sides
open??????  I'm not sure.  Out of time for now.  Need to check the actual
boundary conditions for Sod's problem.  In the 1D code, which matches the
exact solution, I am setting the BCs by copying the inside state to the
exterior state.  I think that is extrapolate BC??? Weird.

-------------------------

12-26-2016 - 8:46 am
The results match up until the shock impinges on the right wall and reflects.
The results from the 1D code match the "exact" result that I got from
the python script.  If I stop the 2d code before the shock reaches the right
wall, the results match the exact and 1d results very well.  On the WIND-US
website, they mentioned that they used a frozen bc at the left and right walls.
The frozen bc is equivalent to making the state at the wall the same as the
initial condition regardless of time.  It seems like a strange boundary
condition to me.  I'm just going to compare my 1D and 2D codes against the
exact solution for t=0.2 s.  They match perfectly at that time.

-------------------------

12-26-2016 10:39 pm
I believe there is something wrong with the fluxes from the
horizontal faces.  The vertical faces seem fine.  One way I could
check this is to run the shock tube going from down-to-up instead
of left-to-right.

-------------------------

12-26-2016 11:02 pm
I tried running the shock tube from down-to-up.  Everything seemed to
work fine.  I think the slow convergence may be due to the fact that
I'm using an explicit scheme.  I believe I could accelerate the convergence
by using implicit residual smoothing.  I've gotta do something.

-------------------------

12-27-2016 2:04 pm
I'm not sure that there is anything wrong with the code.  I've checked and
re-checked the residual_inv function.  I can't find anything wrong.  I'm
thinking that the ramp doesn't look exactly correct because the scheme is
taking a very long time to converge to the steady state.

-------------------------

12-28-2016 7:01 pm
Yesterday was not a good day.  Lost Max yesterday so not much progress.
I added the viscous fluxes.  Need to setup a test case.

-------------------------

12-30-2016 10:03 pm
I didn't work on this yesterday because I was working on a post-doc application.
I need to come up with a manufactured solution to check the Navier-Stokes code.
I'm going to use the one from the paper by Liao, Diskin, Peng and Luo.  Need to
write an operator for the Navier-Stokes equations in Mathematica in order to
determine what source term(s) I should add to the governing equations.

-------------------------

01-01-2017 8:10 pm
Working on adding an order-of-accuracy check using the method of manufactured
solutions.  I'm avoiding temporal accuracy for now and using a steady
solution.

-------------------------

01-01-2017 10:41 pm
I need to find a good way to add the viscous fluxes to all of the boundary
conditions.  I could make inviscid bcs 1000 series and viscous 2000.  I should
also find a way to switch the time steppers between viscous and inviscid.  For
the boundary conditions, I need to be able to provide the primitive variables
as well as the derivatives of the primitive variables for the viscous fluxes.
I need to create a new viscous flux function that takes all of this information
as inputs instead of using element information.  Pick up in apply_bcs in
solver.f90 and flux.f90.

-------------------------

01-02-2017 7:13 pm
I'm almost done with all the modifications necessary for validating the code using
the method of manufactured solutions.  Running out of steam for the day.  I need
to pick up in examples/manufactured/ns_validation.f90.

-------------------------

01-02-2017 10:24 pm
I finished the modifications required for the method of manufactured solutions.
Found one mistake in the enforcement of the boundary conditions for the MMS.
Getting NaNs in the residual_inv subroutine for vertical faces near the
upper right corner.  I'm not sure what is wrong.  I need to check the
residual_visc subroutine along with the flux_visc_state and flux_visc
functions.

-------------------------

01-03-2017 2:26 pm
I have tracked down the NaNs to negative pressures inside the Riemann solver.
I believe this is happening because the orders of magnitude of rho, u, v, E, etc.,
are too small.  That is, errors in the piecewise linear reconstruction are
responsible for producing states that have negative pressures.  I added a check
to the Riemann solver.  I believe I should modify the manufactured solution so that
the order of magnitude is at least one higher.  Alternatively, if my hypothesis is
correct, using a finer mesh should fix this issue by improving the accuracy of the
piecewise linear reconstruction.

-------------------------

01-03-2017 8:32 pm
I believe I tracked down the bugs.  The code is running without NaNs on a steady
solution.  I need to finish implementing the solve_steady subrouine.

-------------------------

01-04-2017 11:02 pm
I finished the solve_steady subroutine, but the convergence is really slow.  I need
to implement local time stepping now.

-------------------------

01/06/2017 12:32 am
I'm not sure what is wrong with the manufactured solution.  I'm going to try
to solve for the boundary layer over a flat plate in the incompressible
regime.  I can't find any mistakes in what I did with the method of manufactured
solution.  rho*v looks strange, as does E_t.  I'm not sure what's wrong.  I need
to either translate the flatplate grid from Plot3D to CGNS or add a function
to read the mesh from the Plot3D file.  Then, I need to finish implementing the
no-slip wall BC in solvers.f90.

-------------------------

01/07/2017 6:55 pm
The compressible Navier-Stokes solver isn't converging.  I implemented no-slip
wall BCs for the bottom wall only.  I used the Green-Gauss method for computing
the gradient at the wall.  It is not converging.  I think I'm going to try local
time stepping for the compression ramp problem and see what happens.

-------------------------

01/07/2017 9:40 pm
The local time stepping doesn't seem to be working even for the inviscid cases.
I'm not sure that it is implemented correctly.  I think I should try a multi-stage
scheme instead of forward Euler.  I can also add the implicit residual smoothing
relatively easily.  I need to check the values of the gradient at the wall for
the no-slip condition too.

-------------------------

01/07/2017 11:56 pm
Working on implementing Upwind Implicit Residual Smoothing (UIRS).  Need to pick
up in acceleration.f90.  I tried a 3-stage method using the "optimized" stage
coefficients given in the book by Blazek.  It is still not working.  I'm not
sure what is wrong...

-------------------------

01/08/2017 9:49 pm
I finished implementing UIRS.  There was a bug of some sort in the call to the
thomas algorithm subroutine.  The lower diagonal was allocated as ld(2:n) where
n is the number of rows of the matrix.  This caused something strange that I
cannot explain.  When I changed the allocation of ld to ld(1:n), but I only
filled in the values from (2:n), everything works.  I'm in the process of writing
unit tests for everything I can think of.  I'm not sure what the problem is.  The
unsteady cases seem to work perfectly, but the steady cases won't converge.  I've
added local time stepping and implicit residual smoothing in an effort to improve
the convergence, but it is not working, even for the inviscid cases.  There has to
be some bug somewhere.  See TODO for a list of what needs to be done.  I think the
approximations for the spectral radii of the viscous flux Jacobian and inviscid
flux Jacobian are wrong.  I have to use CFL numbers on the order of 1x10^(-4)
in order to avoid the solver blowing up right away.

-------------------------

01/12/2017 4:20 pm
Implemented first-order spatial accuracy by using constant extrapolation instead of
piecewise linear.  Need to test it and add a way to turn it on and add it to the
namelist.

-------------------------

01/13/2017 9:50 pm
I'm not sure that my implementation of first-order accuracy is correct.  I just changed
the inviscid residual subroutine so that it uses constant extrapolation instead of
piecewise linear.  Good news is that the compute_timestep_inv is correct.  I checked
it on a uniform grid using two different methods and I got the same result.  The bug
must be somewhere else.  How is it that the code works perfectly for unsteady cases,
but it explodes for steady cases?  How could this be possible?  What are the differences
between the steady and unsteady cases?  The time marching is the only real difference.

-------------------------

01/13/2017 11:47 pm
No matter what, the x-momentum diverges in the ramp case.  I believe something might
be wrong with the implementation somehow.  I need to keep writing unit tests.

-------------------------

01/14/2017 10:55 pm
I somehow got the MMS NS solution to converge when using first-order spatial
accuracy.  I changed something though and now it is broken.  It is returning NaNs.
I need to figure out what I did to mess everything up.  I believe residual smoothing
was being used.

-------------------------

01/15/2017 10:15 pm
I found one bug in the MMS stuff.  I was using R for the gas constant and r for the
result.  Since Fortran is case-insensitive, the behavior was wrong.  I believe there
is still a bug in the MMS or NS solution somewhere.  The y-momentum residuals blow
up after a while.  UIRS causes the residuals to diverge more.  Haven't tested local
time stepping yet.

-------------------------

01/16/2017 11:14 am
Found more issues in the MMS exact solutions and in the source terms.  Local time
stepping now speeds up the convergence.  Now, I need to update mms.f90 using the new
exact solutions and source terms in cns2d/misc/tmp/*.  I need to use sed to replace
\[Rho\] and \[Gamma\] with rho and g.

-------------------------

01/16/2017 3:31 pm
I am close, but not quite there yet.  I updated the source and exact solutions using
the new results, but it still isn't converging quite right.  I need to double check
the following:
- Exact solutions
- Enforcement of boundary conditions
- Viscous fluxes

-------------------------

01/18/2017 10:02 am
It seems to me that there is some mistake somewhere in the code.  The inviscid portion
won't converge.  There has to be a mistake.  The CFL numbers I'm having to use are far
too small.  I need to check and re-check everything.

-------------------------

01/18/2017 2:48 pm
I don't know if I will be able to get this to work.  Apparently, the order of accuracy is
0.5.  I don't know what is wrong.  I'm stuck.

-------------------------

01/19/2017 1:46 pm
The CFL number I was using was far too low.  If I increase the CFL number to more realistic
values, the solver converges for the ramp case.  There are still some issues -- the boundary
elements are not right.  I believe this is because I don't do any residual smoothing on the
boundaries.  I need to figure out what to do on the boundaries.  Maybe CIRS.

-------------------------

01/19/2017 9:30 pm
Found a mistake in the upwind implicit residual smoothing.  I computed the smoothing coefficient
for each direction (i and j) using the spectral radii of the convective flux Jacobian, but I
never changed the smoothing coefficient in the assembly of the system.  It was still set to
epsilon, when it should be epsilon_i and epsilon_j, respectively.  I'm going to fix this and
hope it allows me to use higher values of eps.

-------------------------

01/19/2017 11:09 pm
Adding the boundary residual smoothing seems to mess everything up a bit.  Now, the solver
won't converge.  It blows up with negative pressures.  Not sure what is happening.  I need
to implement the venkatakrishnan limiter to see if that helps with robustness.

-------------------------

01/22/2017 11:48 pm
I've added the limiter by Venkatakrishnan.  I believe I've isolated the problem to the
freestream and extrapolate BCs.  Look at animations in ramp to pick back up in the morning.

-------------------------

01/23/2017 12:09 pm
The solver works fine for the isentropic vortex and the shocktube.  For an inviscid flat
plate, it seems that the boundary conditions cause oscillations to propagate inside
somehow.  Looking at rho v, there are tons of strange oscillations.  I'm going to keep writing
unit tests for everything I can think of.  I'm not sure where the problem is.

-------------------------

01/24/2017 12:12 am
- Set state at ghost cells and solve Riemann problem instead of computing fluxes directly.
- Must be a BC implementation issue.
- Set minimum pressure so that it doesn't go negative.
- Write phi out to file to see where the limiter is being activated.
- Create 5x5 grid and find fluxes, etc by hand and see if the code gives the same.
- Might be a problem with the Riemann solver.

-------------------------

01/24/2017 4:18 pm
Found one major bug in flux.f90.  Specifically, it was in the flux_adv subroutine.  The
total enthalpy was calcuated using H = u4 + p/rho, but u4 = rhoE so it should be
H = u4/u1 + p/rho.  This fixes several issues.

-------------------------

01/26/2017 9:11 pm
Trying to check the code using the method of manufactured solutions, but I'm having issues.
The boundaries are wrong, as is rhou.  The x-momentum is very wrong.  I'm thinking of
enforcing the boundary conditions for the viscous fluxes by setting the state in the
ghost cells and using the averages of the cell-centered values to compute the flux at
the face.  Not sure that will fix the issue.

-------------------------

01/26/2017 10:55 pm
As it turns out, the way I am evaluating the derivatives at the faces is wrong.  According
to Blazek, averaging the cell-centered gradients to find the gradient at the faces can
cause decoupling in the solution on quad and hex meshes.  I need to implement a capability
to compute the gradients at the faces of the cells using the Green-Gauss approach.

-------------------------

01/31/2017 10:31 pm
I believe there was a mistake in the operator for the momentum equations.  I corrected it.
Now, it seems that rho and rhoE are converging to the exact solution, but there is still
a problem with rhou and rhov.  I'm hoping this problem is caused by the gradient computation.
I do see some patterns emerging in rhov which look like a sort of decoupling is taking place.

-------------------------

02/09/2017 10:19 am
Working on adding the Green-Gauss gradient computation.  Having to set the state in
the ghost cells.  I'm doing this in the bcs.f90 file.

-------------------------

02/17/2017 9:37 pm
I added the Green-Gauss gradient computation, but something is still wrong.  I need to
go back and check everything.  The solver doesn't converge on the MMS case.
